{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "data = pd.read_sas('/home/guangya/Downloads/wnv_2245new.sas7bdat')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# origin_data2 = pd.read_csv(\"/home/jallen17/DATA_CPRHD_SES/R_model_data/selected_features_remove_outliers.csv\")\n",
    "# origin_data2 = origin_data2.values\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "data = origin_data\n",
    "x = data.drop(columns=['yrweeks', 'yrwksfid', 'yr_hexid', 'year', 'income1','hexid','PopYesNo'])\n",
    "x_small = x[(x.weeks >= 22) & (x.weeks <= 31)]\n",
    "columns = ['tempc', 'preci', 'templag1', 'templag2', 'templag3', 'templag4',\n",
    "       'precilag1', 'precilag2', 'precilag3', 'precilag4', 'mirmean',\n",
    "       'mirlag1', 'mirlag2', 'mirlag3', 'mirlag4', 'totpop', 'whitepct',\n",
    "       'blackpct', 'asianpct', 'Income', 'dlipct', 'dmipct', 'dhipct',\n",
    "       'Jantemp', 'hpctpreww', 'hpctpostww', 'hpct7089', 'hpctpost90']\n",
    "x_selected = x_small[columns].values\n",
    "y_selected = x_small['wnvbinary'].values\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "dataX = x_selected\n",
    "dataY = y_selected.reshape(-1,1)\n",
    "\n",
    "\n",
    "# # Neural Network\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "# generate training set and test set\n",
    "trainX, testX, trainY, testY = train_test_split(dataX, dataY, test_size = 0.33, shuffle = True)\n",
    "\n",
    "\n",
    "def model_NN_test(model_NN, dataX, dataY):\n",
    "    print(\"Model performance\")\n",
    "    predict_data = model_NN.predict(dataX)\n",
    "    \n",
    "    # Some stats\n",
    "#     print(\"MSE:\", metrics.mean_squared_error(dataY, predict_data))\n",
    "#     print(\"MAE:\", metrics.mean_absolute_error(dataY, predict_data))\n",
    "#     print(\"R2:\", metrics.r2_score(dataY, predict_data))\n",
    "#     errors = abs((dataY - predict_data) / dataY)\n",
    "#     mean_errors = np.mean(errors)\n",
    "#     mean_accuracy = 1 - mean_errors\n",
    "#     print(\"Mean Accuracy:\", mean_accuracy * 100, \"%\")\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.xlabel('True MIR')\n",
    "    plt.ylabel('Predicted MIR')\n",
    "    plt.plot(dataY, predict_data, \"*\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(dataY, label = 'actual data')\n",
    "    plt.plot(predict_data, label = 'predict data')\n",
    "    plt.xlabel('Tract')\n",
    "    plt.ylabel('MIR')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()\n",
    "    \n",
    "    return errors\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "def NN_model():\n",
    "    dropout_rate = 0\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation = \"elu\", input_dim = 180))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, activation = \"elu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, activation = \"elu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation = \"elu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(16, activation = \"elu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(8, activation = \"elu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    model.compile(loss = \"mean_squared_error\", optimizer = \"adam\") \n",
    "    return model\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', preprocessing.StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=NN_model, epochs = 100, batch_size = 32)))\n",
    "pipeline = Pipeline(estimators) \n",
    "kfold = KFold(n_splits=3, random_state=seed)\n",
    "results = cross_val_score(estimators, dataX, dataY, cv=kfold)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "results.mean()\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "dropout_rate = 0.4\n",
    "activation_function = \"elu\" # elu, relu, sigmoid, tanh, linear, softmax\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Dense(16, kernel_initializer='normal', activation = \"elu\", input_dim = trainX_scaled.shape[1]))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation = \"elu\"))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = \"adam\") \n",
    "# mean_absolute_error, mean_squared_error;\n",
    "# SGD, adam, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
    "train_history = model.fit(x = trainX_scaled, y = trainY_scaled, \n",
    "                                    epochs = 500, batch_size = 16, \n",
    "                                    validation_data = (testX_scaled, testY_scaled))\n",
    "model_history = train_history.history\n",
    "time_consumed = time.time() - time_start\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "time_consumed\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "errors_train = model_NN_test(model, trainX_scaled, trainY_scaled, scaler_trainX, scaler_trainY)\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "errors_test = model_NN_test(model, testX_scaled, testY_scaled, scaler_trainX, scaler_trainY)\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "plt.plot(model_history['loss'], label = 'loss')\n",
    "plt.plot(model_history['val_loss'], label = 'val_loss')\n",
    "plt.legend(loc = \"best\")\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "len(errors_test)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "len(errors_test[errors_test<0.5])\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "# save history\n",
    "# with open(\"model_500_history_2.json\", \"w\") as history_file:\n",
    "#     history_file.write(json.dumps(train_history.history))\n",
    "\n",
    "\n",
    "# # In[67]:\n",
    "\n",
    "\n",
    "# # read history\n",
    "# with open(\"model_500_history_2.json\") as history_file:\n",
    "#         model_history = json.loads(history_file.read())\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "# # save model\n",
    "# model.save(\"model_500_2.h5\")\n",
    "\n",
    "\n",
    "# # In[69]:\n",
    "\n",
    "\n",
    "# # read model\n",
    "# model = keras.models.load_model('model_500_2.h5')\n",
    "\n",
    "\n",
    "# # In[70]:\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def NN():\n",
    "    trainX = None\n",
    "    trainY = None\n",
    "    testX = None\n",
    "    testY = None\n",
    "    model = None\n",
    "    score = None\n",
    "    \n",
    "    def __init__ (self,\n",
    "                  dropout_layer_rate = 0.1,\n",
    "                  rnn_dropout_rate = 0.1,\n",
    "                  nb_epoch = 50,\n",
    "                  batch_size = 16,\n",
    "                  loss = 'mean_absolute_error',\n",
    "                  optimizer = 'adam',\n",
    "                  save_model = True,\n",
    "                  save_model_path = ''):\n",
    "\n",
    "        self.dropout_layer_rate = dropout_layer_rate\n",
    "        self.rnn_dropout_rate = rnn_dropout_rate\n",
    "        self.nb_epoch = nb_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer #rmsprop, adam\n",
    "        self.save_model = save_model\n",
    "        self.save_model_path = save_model_path\n",
    "        \n",
    "    def NN_getData(self, trainX, trainY, testX, testY):\n",
    "        self.trainX = trainX\n",
    "        self.trainY = trainY\n",
    "        self.testX = testX\n",
    "        self.testY = testY\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def NN_model_train(self):\n",
    "        trainX = self.trainX\n",
    "        trainY = self.trainY\n",
    "        testX = self.testX\n",
    "        testY = self.testY\n",
    "        model = self.model\n",
    "        dropout_layer_rate = self.dropout_layer_rate\n",
    "        rnn_dropout_rate = self.rnn_dropout_rate\n",
    "        \n",
    "        input_dim = trainX.shape\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
