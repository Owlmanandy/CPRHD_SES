{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (brier_score_loss, precision_score, recall_score,\n",
    "                             f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and extra data of particular periods of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sas('/home/guangya/Downloads/wnv_2245new.sas7bdat') #Data from week 22 to 45, which is what i used for latter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hexid</th>\n",
       "      <th>Input_FID</th>\n",
       "      <th>tempc</th>\n",
       "      <th>preci</th>\n",
       "      <th>yr</th>\n",
       "      <th>weeks</th>\n",
       "      <th>yrweeks</th>\n",
       "      <th>yrwksfid</th>\n",
       "      <th>templag1</th>\n",
       "      <th>templag2</th>\n",
       "      <th>...</th>\n",
       "      <th>wwpct</th>\n",
       "      <th>ehwpct</th>\n",
       "      <th>yr_hexid</th>\n",
       "      <th>Jantemp</th>\n",
       "      <th>PopYesNo</th>\n",
       "      <th>hpctpreww</th>\n",
       "      <th>hpctpostww</th>\n",
       "      <th>hpct7089</th>\n",
       "      <th>hpctpost90</th>\n",
       "      <th>income1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>16.9758</td>\n",
       "      <td>6.046130</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>b'200522'</td>\n",
       "      <td>b'200522130'</td>\n",
       "      <td>15.9957</td>\n",
       "      <td>13.7796</td>\n",
       "      <td>...</td>\n",
       "      <td>27.184466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2005,1'</td>\n",
       "      <td>-3.815482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.979816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>25.3449</td>\n",
       "      <td>58.968242</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>b'200523'</td>\n",
       "      <td>b'200523130'</td>\n",
       "      <td>16.9758</td>\n",
       "      <td>15.9957</td>\n",
       "      <td>...</td>\n",
       "      <td>27.184466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2005,1'</td>\n",
       "      <td>-3.815482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.979816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>21.0872</td>\n",
       "      <td>15.114200</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>b'200524'</td>\n",
       "      <td>b'200524130'</td>\n",
       "      <td>25.3449</td>\n",
       "      <td>16.9758</td>\n",
       "      <td>...</td>\n",
       "      <td>27.184466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2005,1'</td>\n",
       "      <td>-3.815482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.979816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>22.3485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>b'200525'</td>\n",
       "      <td>b'200525130'</td>\n",
       "      <td>21.0872</td>\n",
       "      <td>25.3449</td>\n",
       "      <td>...</td>\n",
       "      <td>27.184466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2005,1'</td>\n",
       "      <td>-3.815482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.979816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>25.7740</td>\n",
       "      <td>6.371029</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>b'200526'</td>\n",
       "      <td>b'200526130'</td>\n",
       "      <td>22.3485</td>\n",
       "      <td>21.0872</td>\n",
       "      <td>...</td>\n",
       "      <td>27.184466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2005,1'</td>\n",
       "      <td>-3.815482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.979816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hexid  Input_FID    tempc      preci      yr  weeks    yrweeks  \\\n",
       "0    1.0      130.0  16.9758   6.046130  2005.0   22.0  b'200522'   \n",
       "1    1.0      130.0  25.3449  58.968242  2005.0   23.0  b'200523'   \n",
       "2    1.0      130.0  21.0872  15.114200  2005.0   24.0  b'200524'   \n",
       "3    1.0      130.0  22.3485   0.000000  2005.0   25.0  b'200525'   \n",
       "4    1.0      130.0  25.7740   6.371029  2005.0   26.0  b'200526'   \n",
       "\n",
       "       yrwksfid  templag1  templag2  ...      wwpct  ehwpct   yr_hexid  \\\n",
       "0  b'200522130'   15.9957   13.7796  ...  27.184466     0.0  b'2005,1'   \n",
       "1  b'200523130'   16.9758   15.9957  ...  27.184466     0.0  b'2005,1'   \n",
       "2  b'200524130'   25.3449   16.9758  ...  27.184466     0.0  b'2005,1'   \n",
       "3  b'200525130'   21.0872   25.3449  ...  27.184466     0.0  b'2005,1'   \n",
       "4  b'200526130'   22.3485   21.0872  ...  27.184466     0.0  b'2005,1'   \n",
       "\n",
       "    Jantemp  PopYesNo  hpctpreww  hpctpostww  hpct7089 hpctpost90    income1  \n",
       "0 -3.815482       1.0        0.0         0.0       0.0        0.0  41.979816  \n",
       "1 -3.815482       1.0        0.0         0.0       0.0        0.0  41.979816  \n",
       "2 -3.815482       1.0        0.0         0.0       0.0        0.0  41.979816  \n",
       "3 -3.815482       1.0        0.0         0.0       0.0        0.0  41.979816  \n",
       "4 -3.815482       1.0        0.0         0.0       0.0        0.0  41.979816  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # Available features in the data set, More description is the final.xlsw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hexid               0\n",
       "Input_FID           0\n",
       "tempc               0\n",
       "preci               0\n",
       "yr                  0\n",
       "weeks               0\n",
       "yrweeks             0\n",
       "yrwksfid            0\n",
       "templag1            0\n",
       "templag2            0\n",
       "templag3            0\n",
       "templag4            0\n",
       "precilag1           0\n",
       "precilag2           0\n",
       "precilag3           0\n",
       "precilag4           0\n",
       "wnvbinary           0\n",
       "mirmean             0\n",
       "year           150510\n",
       "mirlag1             0\n",
       "mirlag2             0\n",
       "mirlag3             0\n",
       "mirlag4             0\n",
       "totpop              0\n",
       "whitepct            0\n",
       "blackpct            0\n",
       "asianpct            0\n",
       "hispanicpct         0\n",
       "Income              0\n",
       "owpct               0\n",
       "dospct              0\n",
       "dlipct              0\n",
       "dmipct              0\n",
       "dhipct              0\n",
       "blpct               0\n",
       "dfpct               0\n",
       "efpct               0\n",
       "mfpct               0\n",
       "shrubpct            0\n",
       "glandpct            0\n",
       "pasturepct          0\n",
       "ccpct               0\n",
       "wwpct               0\n",
       "ehwpct              0\n",
       "yr_hexid            0\n",
       "Jantemp             0\n",
       "PopYesNo            0\n",
       "hpctpreww           0\n",
       "hpctpostww          0\n",
       "hpct7089            0\n",
       "hpctpost90          0\n",
       "income1             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum() # Check na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hexid          0\n",
       "Input_FID      0\n",
       "tempc          0\n",
       "preci          0\n",
       "yr             0\n",
       "weeks          0\n",
       "templag1       0\n",
       "templag2       0\n",
       "templag3       0\n",
       "templag4       0\n",
       "precilag1      0\n",
       "precilag2      0\n",
       "precilag3      0\n",
       "precilag4      0\n",
       "mirmean        0\n",
       "mirlag1        0\n",
       "mirlag2        0\n",
       "mirlag3        0\n",
       "mirlag4        0\n",
       "totpop         0\n",
       "whitepct       0\n",
       "blackpct       0\n",
       "asianpct       0\n",
       "hispanicpct    0\n",
       "Income         0\n",
       "owpct          0\n",
       "dospct         0\n",
       "dlipct         0\n",
       "dmipct         0\n",
       "dhipct         0\n",
       "blpct          0\n",
       "dfpct          0\n",
       "efpct          0\n",
       "mfpct          0\n",
       "shrubpct       0\n",
       "glandpct       0\n",
       "pasturepct     0\n",
       "ccpct          0\n",
       "wwpct          0\n",
       "ehwpct         0\n",
       "Jantemp        0\n",
       "PopYesNo       0\n",
       "hpctpreww      0\n",
       "hpctpostww     0\n",
       "hpct7089       0\n",
       "hpctpost90     0\n",
       "income1        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['wnvbinary','yrweeks','yrwksfid','yr_hexid','year']).isna().sum() # Drop year column so that so na appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = data.drop(columns=['wnvbinary','yrweeks','yrwksfid','yr_hexid','year']).values # Drop extra column\n",
    "y_total = data['wnvbinary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = x_total.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.28479215])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some spot check for data\n",
    "data[data['hexid'] == 1431]['blackpct'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([86.10261915])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['hexid'] == 1831]['whitepct'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.42441054])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['hexid'] == 1831]['dmipct'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.88401563])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['hexid'] == 3121]['income1'].unique() # The Geological and social data is likely a 10 year estimate here, which does not change from 2005-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['yr','templag2','templag3','templag4','precilag2','mirlag1','mirlag2','mirlag3','mirlag4', 'whitepct','owpct','dmipct','dhipct']].values\n",
    "# Data set for the best model described in paper, table5.\n",
    "# However, random forest use a different feature selection algorithm \n",
    "# so that this might not be the optimal one for oue models. Since it's much slower to train all, I will use ALL features for further optimization later\n",
    "y = data['wnvbinary'].values \n",
    "x = x.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2, shuffle = True) # CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_total, testX_total, trainY_total, testY_total = train_test_split(x_total, y_total, test_size = 0.2, shuffle = True) # CV for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_RF_test(model_RF, dataX, dataY):\n",
    "    print(\"Model performance\")\n",
    "    predict_data = model_RF.predict_proba(dataX)\n",
    "    \n",
    "    # Some stats\n",
    "    print(\"Feature Importantce : \")\n",
    "    print(model_RF.feature_importances_)\n",
    "    print(\"Total number of WNV occurence in test set : \" + str(len(dataY[dataY > 0])))\n",
    "    \n",
    "    print(\"Number of WNV occurence the model is able to capture in test set:\" + str(dataY[np.where(predict_data[:,1]  > 0)].sum()))\n",
    "    \n",
    "    print(\"Expected number of WNV occurence of models aussume prediction is normally distributed : \" + str(predict_data[:,1].mean() * len(predict_data)))\n",
    "    print(\"Log loss : \" + str(log_loss(dataY,predict_data)))\n",
    "    \n",
    "    print(\"This is to test the performance of random forest model, ideally, the logloss is low and also it is able to capture most of the WNV occurence, and also it is neither over predicting\" +  \n",
    "          \"nor under predicting\")\n",
    "    \n",
    "    return None # Check how many wnv it predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed: 3.264770030975342\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(trainX_total, trainY_total)\n",
    "time_start = time.time()\n",
    "model_RF1 = RandomForestClassifier(n_estimators=400,\n",
    "                                 n_jobs = -1,\n",
    "                                 max_features=None,\n",
    "                                 max_depth= None,\n",
    "                                 bootstrap=True,\n",
    "                                class_weight='balanced'\n",
    "                                 ) # Use undersampling to see if it worked\n",
    "model_RF1.fit(X_resampled, y_resampled)\n",
    "print(\"time consumed:\", time.time() - time_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance\n",
      "Feature Importantce : \n",
      "[0.00999531 0.01067965 0.01496773 0.01082702 0.0054172  0.02645585\n",
      " 0.02794946 0.02833401 0.03969041 0.03359853 0.01333262 0.01407395\n",
      " 0.01410982 0.01532784 0.02686748 0.13324849 0.11390923 0.11554932\n",
      " 0.01995433 0.13395407 0.00646951 0.00946079 0.00790575 0.00963136\n",
      " 0.00768387 0.00252334 0.01573296 0.01404953 0.01017898 0.01184233\n",
      " 0.00080315 0.0024459  0.0021979  0.00341815 0.00042789 0.00192679\n",
      " 0.00188718 0.00171914 0.00172571 0.00063831 0.02298358 0.\n",
      " 0.01426518 0.01014777 0.01229566 0.01120487 0.00819208]\n",
      "Total number of WNV occurence in test set : 173\n",
      "Number of WNV occurence the model is able to capture in test set:173.0\n",
      "Expected number of WNV occurence of models aussume prediction is normally distributed : 69593.33\n",
      "Log loss : 0.4248442677492819\n",
      "This is to test the performance of random forest model, ideally, the logloss is low and also it is able to capture most of the WNV occurence, and also it is neither over predictingnor under predicting\n"
     ]
    }
   ],
   "source": [
    "model_RF_test(model_RF1,testX_total,testY_total) # The result tend to predict a lot of 1s, which is very biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed: 1.166808843612671\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(trainX, trainY)\n",
    "time_start = time.time()\n",
    "model_RF2 = RandomForestClassifier(n_estimators=400,\n",
    "                                 n_jobs = -1,\n",
    "                                 max_features=None,\n",
    "                                 max_depth= None,\n",
    "                                 bootstrap=True,\n",
    "                                class_weight='balanced'\n",
    "                                 ) # Use undersampling to see if it worked\n",
    "model_RF2.fit(X_resampled, y_resampled)\n",
    "print(\"time consumed:\", time.time() - time_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance\n",
      "Feature Importantce : \n",
      "[0.02332565 0.07673163 0.09381062 0.08244171 0.04115731 0.09283884\n",
      " 0.32511096 0.03987311 0.05722872 0.04018178 0.02340537 0.06687365\n",
      " 0.03702065]\n",
      "Total number of WNV occurence in test set : 196\n",
      "Number of WNV occurence the model is able to capture in test set:195.0\n",
      "Expected number of WNV occurence of models aussume prediction is normally distributed : 73071.56249999999\n",
      "Log loss : 0.42897848898311103\n",
      "This is to test the performance of random forest model, ideally, the logloss is low and also it is able to capture most of the WNV occurence, and also it is neither over predictingnor under predicting\n"
     ]
    }
   ],
   "source": [
    "model_RF_test(model_RF2,testX,testY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed: 307.3307168483734\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "model_RF3 = RandomForestClassifier(n_estimators=200,\n",
    "                                 n_jobs = -1,\n",
    "                                 max_features='sqrt',\n",
    "                                 max_depth= 20,\n",
    "                                 bootstrap=True,\n",
    "                                   min_samples_leaf= 2,\n",
    "                                class_weight='balanced'\n",
    "                                 ) # Try more trees and see if calibration curve gets better\n",
    "model_RF3.fit(trainX_total, trainY_total)\n",
    "print(\"time consumed:\", time.time() - time_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sorted(model_RF3.feature_importances_)[::-1]\n",
    "seq = [list(model_RF3.feature_importances_).index(v) for v in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 16, 17, 19, 8, 14, 18, 9, 7, 5]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance\n",
      "Feature Importantce : \n",
      "[1.30942271e-02 1.28020934e-02 2.92368487e-02 1.19465584e-02\n",
      " 7.07868054e-03 4.19247572e-02 2.91652172e-02 4.69769293e-02\n",
      " 6.08182076e-02 4.90170180e-02 1.13150864e-02 1.15022790e-02\n",
      " 1.32276167e-02 1.27103614e-02 5.50808196e-02 9.72655123e-02\n",
      " 7.87749447e-02 7.80864630e-02 5.01764878e-02 7.08532494e-02\n",
      " 8.85207640e-03 9.74098519e-03 8.80785359e-03 1.12414583e-02\n",
      " 9.87450040e-03 6.71593176e-03 1.24806795e-02 1.14679958e-02\n",
      " 1.23319782e-02 1.02753625e-02 1.17618205e-03 8.00185418e-03\n",
      " 9.13261608e-04 3.29746529e-03 4.22286487e-04 4.30764953e-03\n",
      " 1.68786058e-03 9.07328043e-04 4.42005112e-03 7.72870641e-05\n",
      " 2.79016966e-02 0.00000000e+00 1.64946315e-02 9.70867099e-03\n",
      " 1.27331784e-02 1.49233092e-02 1.01851078e-02]\n",
      "Total number of WNV occurence in test set : 173\n",
      "Number of WNV occurence the model is able to capture in test set:165.0\n",
      "Expected number of WNV occurence of models aussume prediction is normally distributed : 13746.057522374354\n",
      "Log loss : 0.06939181433886929\n",
      "This is to test the performance of random forest model, ideally, the logloss is low and also it is able to capture most of the WNV occurence, and also it is neither over predictingnor under predicting\n"
     ]
    }
   ],
   "source": [
    "model_RF_test(model_RF3,testX_total,testY_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hexid', 'Input_FID', 'tempc', 'preci', 'yr', 'weeks', 'templag1',\n",
       "       'templag2', 'templag3', 'templag4', 'precilag1', 'precilag2',\n",
       "       'precilag3', 'precilag4', 'mirmean', 'mirlag1', 'mirlag2', 'mirlag3',\n",
       "       'mirlag4', 'totpop', 'whitepct', 'blackpct', 'asianpct', 'hispanicpct',\n",
       "       'Income', 'owpct', 'dospct', 'dlipct', 'dmipct', 'dhipct', 'blpct',\n",
       "       'dfpct', 'efpct', 'mfpct', 'shrubpct', 'glandpct', 'pasturepct',\n",
       "       'ccpct', 'wwpct', 'ehwpct', 'Jantemp', 'PopYesNo', 'hpctpreww',\n",
       "       'hpctpostww', 'hpct7089', 'hpctpost90', 'income1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['wnvbinary','yrweeks','yrwksfid','yr_hexid','year']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed: 218.0876429080963\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "model_RF4 = RandomForestClassifier(n_estimators=200,\n",
    "                                 n_jobs = -1,\n",
    "                                 max_features='sqrt',\n",
    "                                 max_depth= 20,\n",
    "                                 bootstrap=True,\n",
    "                                   min_samples_leaf= 2,\n",
    "                                class_weight='balanced'\n",
    "                                 ) # Try more trees and see if calibration curve gets better\n",
    "model_RF4.fit(trainX, trainY)\n",
    "print(\"time consumed:\", time.time() - time_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance\n",
      "Feature Importantce : \n",
      "[0.02621741 0.08807811 0.09189799 0.09668619 0.03990629 0.14748003\n",
      " 0.14935428 0.11992112 0.08589193 0.03846456 0.02059316 0.057597\n",
      " 0.03791192]\n",
      "Total number of WNV occurence in test set : 196\n",
      "Number of WNV occurence the model is able to capture in test set:181.0\n",
      "Expected number of WNV occurence of models aussume prediction is normally distributed : 13670.897052778864\n",
      "Log loss : 0.06785630091527631\n",
      "This is to test the performance of random forest model, ideally, the logloss is low and also it is able to capture most of the WNV occurence, and also it is neither over predictingnor under predicting\n"
     ]
    }
   ],
   "source": [
    "model_RF_test(model_RF4,testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['yr', 'templag2', 'templag3', 'templag4', 'precilag2', 'mirlag1',\n",
       "       'mirlag2', 'mirlag3', 'mirlag4', 'whitepct', 'owpct', 'dmipct',\n",
       "       'dhipct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['yr','templag2','templag3','templag4','precilag2','mirlag1','mirlag2','mirlag3','mirlag4', 'whitepct','owpct','dmipct','dhipct']].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mirlag3', 'whitepct', 'templag4', 'precilag1', 'mirlag2', 'mirlag4'], dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['wnvbinary','yrweeks','yrwksfid','yr_hexid','year']).columns[[17,20,9,10,16,18]]West Nile Virus Chicago: Wayne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>templag2</th>\n",
       "      <th>templag3</th>\n",
       "      <th>templag4</th>\n",
       "      <th>precilag1</th>\n",
       "      <th>mirlag1</th>\n",
       "      <th>mirlag2</th>\n",
       "      <th>mirlag3</th>\n",
       "      <th>whitepct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.7796</td>\n",
       "      <td>16.7306</td>\n",
       "      <td>9.0730</td>\n",
       "      <td>0.019091</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>65.74257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.9957</td>\n",
       "      <td>13.7796</td>\n",
       "      <td>16.7306</td>\n",
       "      <td>6.046130</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>65.74257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.9758</td>\n",
       "      <td>15.9957</td>\n",
       "      <td>13.7796</td>\n",
       "      <td>58.968242</td>\n",
       "      <td>2.50278</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>65.74257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.3449</td>\n",
       "      <td>16.9758</td>\n",
       "      <td>15.9957</td>\n",
       "      <td>15.114200</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.50278</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>65.74257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0872</td>\n",
       "      <td>25.3449</td>\n",
       "      <td>16.9758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.50278</td>\n",
       "      <td>65.74257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   templag2  templag3  templag4  precilag1  mirlag1  mirlag2  mirlag3  \\\n",
       "0   13.7796   16.7306    9.0730   0.019091  0.00000  0.00000  0.00000   \n",
       "1   15.9957   13.7796   16.7306   6.046130  0.00000  0.00000  0.00000   \n",
       "2   16.9758   15.9957   13.7796  58.968242  2.50278  0.00000  0.00000   \n",
       "3   25.3449   16.9758   15.9957  15.114200  0.00000  2.50278  0.00000   \n",
       "4   21.0872   25.3449   16.9758   0.000000  0.00000  0.00000  2.50278   \n",
       "\n",
       "   whitepct  \n",
       "0  65.74257  \n",
       "1  65.74257  \n",
       "2  65.74257  \n",
       "3  65.74257  \n",
       "4  65.74257  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.drop(columns=['wnvbinary','yrweeks','yrwksfid','yr_hexid','year']).columns[[7,8,9,10,15,16,17,20]]].head() # From the above 3 feature importance of models, we can manually select \n",
    "# about 7 features which is mostly important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_selected = data[data.drop(columns=['wnvbinary','yrweeks','yrwksfid','yr_hexid','year']).columns[[7,8,9,10,15,16,17,20]]]\n",
    "y_selected = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above model, we can see that random forest, although is not very good, can actually capture someinformation. So we will try formal Cross validation on selected features and see if it gets betterz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipnelines for later for wrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_sel, testX_sel, trainY_sel, testY_sel = train_test_split(x_selected.values, y_selected, test_size = 0.2, shuffle = True) # CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed: 6569.04248213768\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "params_RF_grid_1 = {\n",
    "    'n_estimators' : [500, 1000],\n",
    "    'max_features' : [90, 'sqrt', None],\n",
    "    'max_depth' : [10, None],\n",
    "    'min_samples_leaf' : [1,2]\n",
    "}\n",
    "CV_model_RF_1 = GridSearchCV(model_RF, params_RF_grid_1, scoring='neg_log_loss',cv=5)\n",
    "CV_model_RF_1.fit(x_selected, dataY)\n",
    "print(\"time consumed:\", time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='sqrt', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=2, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_model_RF_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_model_RF_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed: 974.386381149292\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "model_RF_best_1 = RandomForestClassifier(n_estimators=800,\n",
    "                                 n_jobs = -1,\n",
    "                                 max_features=\"sqrt\",\n",
    "                                 max_depth=None,\n",
    "                                 bootstrap=True,\n",
    "                                 min_samples_leaf=2\n",
    "                                 )\n",
    "model_RF_best_1.fit(trainX_sel,trainY_sel)\n",
    "print(\"Time consumed:\", time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance\n",
      "Feature Importantce : \n",
      "[0.13570302 0.13524317 0.13471302 0.12046497 0.12085287 0.12269303\n",
      " 0.12148794 0.10884199]\n",
      "Total number of WNV occurence in test set : 174\n",
      "Number of WNV occurence the model is able to capture in test set:128.0\n",
      "Expected number of WNV occurence of models aussume prediction is normally distributed : 185.4557672240931\n",
      "Log loss : 0.008748338479888089\n",
      "This is to test the performance of random forest model, ideally, the logloss is low and also it is able to capture most of the WNV occurence, and also it is neither over predictingnor under predicting\n"
     ]
    }
   ],
   "source": [
    "model_RF_test(model_RF_best_1,testX_sel,testY_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "params_RF_grid_2 = {\n",
    "    'n_estimators' : [800, 1200],\n",
    "    'max_features' : ['sqrt', 5],\n",
    "    'min_samples_leaf' : [2,3]\n",
    "}\n",
    "CV_model_RF_2 = GridSearchCV(model_RF, params_RF_grid_2, cv=5)\n",
    "CV_model_RF_2.fit(dataX, dataY)\n",
    "print(\"time consumed:\", time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-04b2228e3225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCV_model_RF_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CV_model_RF_2.fit(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_model_RF_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed: 263.9204020500183\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "model_RF_best_2 = RandomForestRegressor(n_estimators=1500,\n",
    "                                 criterion=\"mse\",\n",
    "                                 n_jobs = -1,\n",
    "                                 max_features=None,\n",
    "                                 max_depth=None,\n",
    "                                 bootstrap=True,\n",
    "                                 min_samples_leaf=2\n",
    "                                 )\n",
    "model_RF_best_2.fit(trainX, trainY)\n",
    "print(\"Time consumed:\", time.time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed: 998.9455091953278\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, None, 110],\n",
    "    'max_features': ['sqrt', 4],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [500, 2000, 4000, 1000]\n",
    "}\n",
    "CV_model_RF_3 = GridSearchCV(model_RF_best_2, params_RF_grid_3, cv=5)\n",
    "CV_model_RF_3.fit(dataX, dataY)\n",
    "print(\"time consumed:\", time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='log2', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=2, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
       "                      n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_model_RF_3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'log2', 'min_samples_leaf': 2, 'n_estimators': 3000}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_model_RF_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed: 45.644662857055664\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "model_RF_best_3 = RandomForestRegressor(n_estimators=8000,\n",
    "                                 criterion=\"mse\",\n",
    "                                 n_jobs = -1,\n",
    "                                 max_features=\"log2\",\n",
    "                                 max_depth=None,\n",
    "                                 bootstrap=True,\n",
    "                                 min_samples_leaf=2\n",
    "                                 )\n",
    "model_RF_best_3.fit(trainX, trainY)\n",
    "print(\"Time consumed:\", time.time() - time_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
